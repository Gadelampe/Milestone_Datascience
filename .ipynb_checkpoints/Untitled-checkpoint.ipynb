{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "listContentRows = []\n",
    "\n",
    "with open('news_sample.csv', encoding=\"utf8\", newline='') as csvfile:\n",
    "    reader = csv.DictReader(csvfile)\n",
    "    for row in reader:\n",
    "        listContentRows.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### data tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get uniq tags\n",
    "uniqTypes = []\n",
    "\n",
    "with open('SQL setup/type_clean.csv', 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"id\", \"name\"])\n",
    "    for i in range (len(listContentRows) - 1):\n",
    "        if (not (listContentRows[i]['type'] in uniqTypes)):\n",
    "            uniqTypes.append(listContentRows[i]['type'])\n",
    "            writer.writerow([len(uniqTypes) - 1, listContentRows[i]['type']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get uniq tags\n",
    "uniqTags = []\n",
    "\n",
    "for article in listContentRows:\n",
    "    tagsList = article[\"tags\"].split(\",\")\n",
    "    \n",
    "    for tags in tagsList:\n",
    "        if (tags != \"\"):\n",
    "            if (not (tags in uniqTags)):\n",
    "                uniqTags.append(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0\n",
    "\n",
    "with open('SQL setup/tags_clean.csv', 'w', encoding=\"utf8\", newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"id\", \"name\"])\n",
    "    for i in uniqTags:\n",
    "        writer.writerow([counter, i])\n",
    "        counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get uniq authors\n",
    "uniqAuthors = []\n",
    "\n",
    "for article in listContentRows:\n",
    "    authorList = article[\"authors\"].split(\",\")\n",
    "    \n",
    "    for author in authorList:\n",
    "        if (author != \"\"):\n",
    "            if (not (author in uniqAuthors)):\n",
    "                uniqAuthors.append(author.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('SQL setup/authors_clean.csv', 'w', encoding=\"utf8\", newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"id\", \"name\"])\n",
    "    counter = 0\n",
    "    for i in uniqAuthors:\n",
    "        writer.writerow([counter,i])\n",
    "        counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "uniqDomains = []\n",
    "\n",
    "with open('SQL setup/domain_name_clean.csv', 'w', encoding=\"utf8\", newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"id\",\"name\"])\n",
    "    for i in range (len(listContentRows) - 1):\n",
    "        if (not (listContentRows[i]['domain'] in uniqDomains)):\n",
    "            writer.writerow([len(uniqDomains),listContentRows[i]['domain']])\n",
    "            uniqDomains.append(listContentRows[i]['domain'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "uniq_meta_keyword = []\n",
    "\n",
    "with open('SQL setup/meta_keywords_clean.csv', 'w', encoding=\"utf8\", newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"id\",\"name\"])\n",
    "    for i in listContentRows:\n",
    "        for meta_keyword in i[\"meta_keywords\"].split(\",\"):\n",
    "            if (meta_keyword == \"['']\"):\n",
    "                continue\n",
    "                \n",
    "            meta_keyword = re.sub(\"'|\\[|\\]\", \"\", meta_keyword.strip())\n",
    "            if (not (meta_keyword in uniq_meta_keyword)):\n",
    "                writer.writerow([len(uniq_meta_keyword),meta_keyword])\n",
    "                uniq_meta_keyword.append(meta_keyword)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### relational tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getIdFromName (name, dataset):\n",
    "    with open('SQL setup/' + dataset + '.csv', 'r', encoding=\"utf8\", newline='') as file:\n",
    "        reader = csv.DictReader(file)\n",
    "        \n",
    "        for item in reader:\n",
    "            if (item['name'].strip() == name):\n",
    "                return int(item['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('SQL setup/tags_in.csv', 'w', encoding=\"utf8\", newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"id\", \"name\"])\n",
    "    for i in listContentRows:\n",
    "        for tag in i[\"tags\"].split(','):\n",
    "            if (tag == \"\"):\n",
    "                continue\n",
    "            tag = tag.strip()\n",
    "            writer.writerow([i[\"id\"],getIdFromName(tag, 'tags_clean')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('SQL setup/author_in.csv', 'w', encoding=\"utf8\", newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"id\", \"name\"])\n",
    "    for i in listContentRows:\n",
    "        for author in i[\"authors\"].split(','):\n",
    "            if (author == \"\"):\n",
    "                continue\n",
    "            author = author.strip()\n",
    "            writer.writerow([i[\"id\"],getIdFromName(author, 'authors_clean')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('SQL setup/meta_keywords_in.csv', 'w', encoding=\"utf8\", newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"id\", \"name\"])\n",
    "    for i in listContentRows:\n",
    "        for meta_keywords in i[\"meta_keywords\"].split(','):\n",
    "            if (meta_keywords == \"['']\"):\n",
    "                continue\n",
    "            meta_keywords = re.sub(\"'|\\[|\\]\", \"\", meta_keywords.strip())\n",
    "            \n",
    "            writer.writerow([i[\"id\"],getIdFromName(meta_keywords, 'meta_keywords_clean')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('SQL setup/article_clean.csv', 'w', encoding='utf8', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"id\", \"domain\", \"type\", \"url\", \"content\", \"title\", \"meta_description\", \"scraped_at\",  \"updated_at\", \"inserted_at\"])\n",
    "    for i in range (len(listContentRows) - 1):\n",
    "        \n",
    "        writer.writerow([int(listContentRows[i]['id']), getIdFromName(listContentRows[i]['domain'], \"domain_name_clean\"), getIdFromName(listContentRows[i]['type'], \"type_clean\"), listContentRows[i]['url'], listContentRows[i]['content'], listContentRows[i]['title'], listContentRows[i]['meta_description'], listContentRows[i][\"scraped_at\"], listContentRows[i][\"updated_at\"], listContentRows[i][\"inserted_at\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
